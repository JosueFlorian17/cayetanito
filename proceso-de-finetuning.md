pip install unsloth accelerate transformers datasets peft

# ğŸ§  Fine-tuning de Gemma 3 4B con Unsloth (nutriciÃ³n infantil PerÃº ğŸ‡µğŸ‡ª)

Este documento describe todo el proceso para realizar fine-tuning eficiente del modelo `google/gemma-3-4b-pt` usando LoRA, Unsloth y un dataset personalizado con 100 ejemplos de preguntas/respuestas para educaciÃ³n alimentaria infantil con contexto peruano.

---

## âœ… Requisitos previos

- Python 3.10 o superior
- GPU con soporte BF16 o FP16
- Entorno virtual (`venv`) activado

Instalar dependencias:

pip install unsloth accelerate transformers datasets peft

---

## ğŸ—‚ï¸ Estructura esperada de archivos

tu_proyecto/
â”œâ”€â”€ nutricion_dataset.json     # Dataset con 100 ejemplos
â”œâ”€â”€ script_finetuning.py       # Script de entrenamiento
â””â”€â”€ venv/                      # (opcional) entorno virtual

---

## ğŸ“„ Formato del dataset (nutricion_dataset.json)

Debe ser una lista de objetos con campos `prompt` y `response`.

[
  {
    "prompt": "Â¿Por quÃ© es importante tomar desayuno antes de ir al colegio?",
    "response": "Porque el desayuno te da energÃ­a para aprender, jugar y concentrarte mejor en clase."
  },
  ...
]

---

## ğŸ§ª Script completo de entrenamiento

from unsloth import FastLanguageModel
from transformers import TrainingArguments, Trainer
from datasets import load_dataset
import torch

# 1. Cargar modelo base Gemma 3 4B
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = "google/gemma-3-4b-pt",
    max_seq_length = 2048,
    dtype = torch.float16,
    load_in_4bit = True,
)

# 2. Activar LoRA
model = FastLanguageModel.get_peft_model(
    model,
    r = 8,
    lora_alpha = 16,
    lora_dropout = 0.05,
    bias = "none",
    task_type = "CAUSAL_LM",
)

# 3. Cargar el dataset personalizado
dataset = load_dataset("json", data_files="nutricion_dataset.json", split="train")

# 4. Formatear los ejemplos en estilo instruct
def format_example(example):
    return {
        "text": f"<s>[INST] {example['prompt']} [/INST] {example['response']}</s>"
    }

dataset = dataset.map(format_example)

# 5. Preparar el modelo para entrenamiento
FastLanguageModel.for_training(model)

# 6. Argumentos de entrenamiento
training_args = TrainingArguments(
    output_dir = "finetuned-gemma-nutricion",
    per_device_train_batch_size = 2,
    gradient_accumulation_steps = 4,
    num_train_epochs = 5,
    learning_rate = 2e-5,
    logging_steps = 5,
    save_steps = 20,
    save_total_limit = 2,
    bf16 = torch.cuda.is_available(),
    fp16 = not torch.cuda.is_bf16_supported(),
    lr_scheduler_type = "cosine",
    optim = "adamw_8bit"
)

# 7. Entrenador
trainer = Trainer(
    model = model,
    train_dataset = dataset,
    args = training_args,
    tokenizer = tokenizer,
)

# 8. Ejecutar entrenamiento
trainer.train()

---

## ğŸ“¦ Salida esperada

Una carpeta `finetuned-gemma-nutricion/` con los siguientes archivos:

- `adapter_model.bin`
- `adapter_config.json`
- `trainer_state.json`

Esta carpeta contiene el fine-tuning LoRA que puedes cargar para hacer inferencia especializada.

---

## ğŸ§  Siguientes pasos sugeridos

- Usar el modelo fine-tuneado con tu script de inferencia.
- Integrar el sistema de prompt engineering personalizado por aula.
- Conectarlo a un flujo RAG si deseas inyectar contexto actualizado.
- Validar respuestas con niÃ±os o docentes reales antes de producciÃ³n.
